{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066 valid rules before extension\n"
     ]
    }
   ],
   "source": [
    "# Load and process ground truth\n",
    "ground_truth = pd.read_csv(\"test-ground-truth.csv\").fillna(\"\")\n",
    "ground_truth[\"fromGroupArtifacts\"] = ground_truth[\"fromGroupArtifacts\"].apply(lambda x: x.split(\";\"))\n",
    "ground_truth[\"toGroupArtifacts\"] = ground_truth[\"toGroupArtifacts\"].apply(lambda x: x.split(\";\"))\n",
    "valid_rules = set()\n",
    "for index, row in ground_truth.iterrows():\n",
    "    valid_rules.update(itertools.product(row[\"fromGroupArtifacts\"], row[\"toGroupArtifacts\"]))\n",
    "print(\"{} valid rules before extension\".format(len(valid_rules)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 libraries removed, 65 remaining\n"
     ]
    }
   ],
   "source": [
    "# Load recommendation results\n",
    "results = pd.read_csv(\"recommend-output-xyl.csv\")\n",
    "\n",
    "# Remove recommendation result with same group ID (No need, seems to be already done in LibraryRecommendJob)\n",
    "# results = results[results.apply(lambda x: x[\"fromGroupArtifact\"].split(\":\")[0] != x[\"toGroupArtifact\"].split(\":\")[0], axis=1)]\n",
    "\n",
    "# Remove all recommendation result for fromLib if no ground truth rules in any of the (fromLib, toLib) pairs\n",
    "from_lib_to_remove = set()\n",
    "for from_lib, df in results.groupby(by=\"fromGroupArtifact\"):\n",
    "    if all((from_lib, row[\"toGroupArtifact\"]) not in valid_rules for index, row in df.iterrows()):\n",
    "        from_lib_to_remove.add(from_lib)\n",
    "results = results[~results[\"fromGroupArtifact\"].isin(from_lib_to_remove)]\n",
    "print(\"{} libraries removed, {} remaining\".format(len(from_lib_to_remove), len(set(results[\"fromGroupArtifact\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following evaluation metrics\n",
    "1. Precision@k\n",
    "2. Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 out of 3066 rules exist in the data\n",
      "Top  1: Precision = 0.800, Recall = 0.209, F-Measure = 0.331\n",
      "Top  2: Precision = 0.725, Recall = 0.349, F-Measure = 0.472\n",
      "Top  3: Precision = 0.655, Recall = 0.450, F-Measure = 0.533\n",
      "Top  4: Precision = 0.568, Recall = 0.506, F-Measure = 0.535\n",
      "Top  5: Precision = 0.500, Recall = 0.546, F-Measure = 0.522\n",
      "Top  6: Precision = 0.466, Recall = 0.602, F-Measure = 0.525\n",
      "Top  7: Precision = 0.430, Recall = 0.639, F-Measure = 0.514\n",
      "Top  8: Precision = 0.395, Recall = 0.663, F-Measure = 0.495\n",
      "Top  9: Precision = 0.370, Recall = 0.691, F-Measure = 0.482\n",
      "Top 10: Precision = 0.348, Recall = 0.715, F-Measure = 0.468\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "top_rules = [list() for x in range(0, top_k)]\n",
    "valid_rules_in_result = set(zip(results[\"fromGroupArtifact\"], results[\"toGroupArtifact\"])) & valid_rules\n",
    "print(\"{} out of {} rules exist in the data\".format(len(valid_rules_in_result), len(valid_rules)))\n",
    "\n",
    "for from_lib, result in results.groupby(by=\"fromGroupArtifact\"):\n",
    "    to_libs = result.sort_values(by=\"confidence\", ascending=False)[\"toGroupArtifact\"]\n",
    "    for k, to_lib in enumerate(to_libs):\n",
    "        if k >= top_k:\n",
    "            continue\n",
    "        top_rules[k].append((from_lib, to_lib))\n",
    "for k in range(1, top_k):\n",
    "    top_rules[k] += top_rules[k - 1]\n",
    "for k in range(0, top_k):\n",
    "    precision = len([x for x in top_rules[k] if x in valid_rules]) / len(top_rules[k])\n",
    "    recall = len([x for x in top_rules[k] if x in valid_rules]) / len(valid_rules_in_result)\n",
    "    f_measure = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Top {:2}: Precision = {:0.3f}, Recall = {:0.3f}, F-Measure = {:0.3f}\".format(k + 1, precision, recall, f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
