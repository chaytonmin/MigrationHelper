{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1: How many possible ground truth rules exist in data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import random\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient(\"mongodb://migration_helper:HeHMgt2020@da1.eecs.utk.edu:27020/migration_helper\"\n",
    "                           \"?authSource=migration_helper\").migration_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404339"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.wocDepSeq3.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#seqs = 404339, #repos = 21358\n"
     ]
    }
   ],
   "source": [
    "repo_names = set()\n",
    "seqs = []\n",
    "for seq in db.wocDepSeq3.find():\n",
    "    repo_names.add(seq[\"repoName\"])\n",
    "    seqs.append(seq)\n",
    "print(\"#seqs = {}, #repos = {}\".format(len(seqs), len(repo_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#seqs len >= 2: 147220\n",
      "#seqs len >= 3: 102199\n"
     ]
    }
   ],
   "source": [
    "print(\"#seqs len >= 2: {}\".format(len([x for x in seqs if len(x[\"seq\"]) >= 2])))\n",
    "print(\"#seqs len >= 3: {}\".format(len([x for x in seqs if len(x[\"seq\"]) >= 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#seqs = 147220, #repos = 14239\n"
     ]
    }
   ],
   "source": [
    "seqs = [x for x in seqs if len(x[\"seq\"]) >= 2]\n",
    "repo_names = set(seq[\"repoName\"] for seq in seqs)\n",
    "print(\"#seqs = {}, #repos = {}\".format(len(seqs), len(repo_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3878"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load possible ground truth data\n",
    "possible_ground_truth = pd.read_csv(\"possible-ground-truth-2014.csv\")\n",
    "from2tolibs = dict()\n",
    "for from_lib, rows in possible_ground_truth.groupby(by=\"fromGroupArtifact\"):\n",
    "    from2tolibs[from_lib] = list(rows[\"toGroupArtifact\"])\n",
    "len(possible_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total = 86048, # rules = 1588, # repos = 3325, # different start commit = 14255\n"
     ]
    }
   ],
   "source": [
    "possible_migrations = []\n",
    "for seq in seqs:\n",
    "    for i, item in enumerate(seq[\"seq\"]):\n",
    "        for chg in item[\"changes\"]:\n",
    "            if chg.startswith(\"-\") and chg[1:] in from2tolibs:\n",
    "                from_lib = chg[1:]\n",
    "                end_id = i\n",
    "                start_id = 0\n",
    "                for j in range(0, i + 1):\n",
    "                    if \"+\" + from_lib in seq[\"seq\"][j][\"changes\"]:\n",
    "                        start_id = j\n",
    "                for k in range(start_id, end_id + 1):\n",
    "                    for to_lib in from2tolibs[from_lib]:\n",
    "                        if \"+\" + to_lib in seq[\"seq\"][k][\"changes\"]:\n",
    "                            migration = {\n",
    "                                \"fromLib\": from_lib,\n",
    "                                \"toLib\": to_lib,\n",
    "                                \"repoName\": seq[\"repoName\"], \n",
    "                                \"fileName\": seq[\"fileName\"],\n",
    "                                \"startCommit\": seq[\"seq\"][k][\"commit\"],\n",
    "                                \"endCommit\": seq[\"seq\"][end_id][\"commit\"],\n",
    "                                \"startCommitChanges\": \"\\n\".join(seq[\"seq\"][k][\"changes\"]),\n",
    "                                \"endCommitChanges\": \"\\n\".join(seq[\"seq\"][end_id][\"changes\"]),\n",
    "                            }\n",
    "                            possible_migrations.append(migration) \n",
    "possible_migrations = pd.DataFrame(possible_migrations)\n",
    "print(\"# total = {}, # rules = {}, # repos = {}, # different start commit = {}\".format(\n",
    "    len(possible_migrations),\n",
    "    len(set(zip(possible_migrations[\"fromLib\"], possible_migrations[\"toLib\"]))),\n",
    "    len(set(possible_migrations[\"repoName\"])),\n",
    "    len(set(possible_migrations[\"startCommit\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = zip(possible_ground_truth[\"fromGroupArtifact\"], possible_ground_truth[\"toGroupArtifact\"])\n",
    "rules_in_depseq = set(zip(possible_migrations[\"fromLib\"], possible_migrations[\"toLib\"]))\n",
    "possible_ground_truth[\"inDepSeq\"] = [x in rules_in_depseq for x in rules]\n",
    "possible_ground_truth.to_csv(\"possible-ground-truth-2014.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_migrations.to_csv(\"possible-migrations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add commit message and timestamp to `possible-migrations.csv`, using `scripts/extend_possible_migrations.py`, then we do the tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for (from_lib, to_lib), rows in possible_migrations.groupby(by=[\"fromLib\", \"toLib\"]):\n",
    "    # print(from_lib, to_lib, len(rows), len(set(rows[\"repoName\"])), len(set(rows[\"startCommit\"])))\n",
    "    repos = list(set(rows[\"repoName\"]))\n",
    "    sample_size = min(len(repos), max(10, int(len(repos) * 0.10)))\n",
    "    random.shuffle(repos)\n",
    "    sample_repos = repos[0:sample_size]\n",
    "    for repo_name, rows_by_repo in rows.groupby(by=\"repoName\"):\n",
    "        if repo_name in sample_repos:\n",
    "            samples.append(rows_by_repo.sample(min(len(rows_by_repo), 5)).iloc[0])\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(samples).to_csv(\"possible-migrations-sampled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7475247524752475\n"
     ]
    }
   ],
   "source": [
    "def get_lib_parts(lib_name: str) -> list:\n",
    "    parts = re.findall(r\"[\\w']+\", lib_name.lower())\n",
    "    useless = [\"com\", \"org\", \"impl\"]\n",
    "    parts = [x for x in parts if len(x) >= 3 and x not in useless]\n",
    "    return parts\n",
    "def seem_like_migration(from_lib: str, to_lib: str, start_msg: str, end_msg: str) -> bool:\n",
    "    start_msg = start_msg.lower()\n",
    "    end_msg = end_msg.lower()\n",
    "    from_lib_parts = get_lib_parts(from_lib)\n",
    "    to_lib_parts = get_lib_parts(to_lib)\n",
    "    add_keywords = [\"use\", \"adopt\", \"introduc\", \"upgrad\", \"updat\", \"采用\", \"升级\"]\n",
    "    remove_keywords = [\"remove\", \"abandon\"]\n",
    "    migration_keywords = [\"migrat\", \"switch\", \"replac\", \"instead\", \"move\", \"swap\"\n",
    "                          \"unify\", \"convert\", \"chang\", \"迁移\", \"替换\", \"修改\"]\n",
    "    cleanup_keywords = [\"pom\", \"clean\", \"remove\"]\n",
    "    if start_msg == end_msg:\n",
    "        if any(x in start_msg for x in to_lib_parts):\n",
    "            if (any(x in start_msg for x in from_lib_parts) \n",
    "                or any(x in start_msg for x in migration_keywords) \n",
    "                or any(x in start_msg for x in add_keywords)):\n",
    "                return True\n",
    "        if any(x in start_msg for x in from_lib_parts) and any(x in start_msg for x in migration_keywords):\n",
    "            return True\n",
    "    else:\n",
    "        if (any(x in start_msg for x in from_lib_parts) and any(x in start_msg for x in add_keywords)\n",
    "            and any(x in end_msg for x in to_lib_parts) and any(x in end_msg for x in remove_keywords)):\n",
    "            return True\n",
    "        \"\"\"\n",
    "        if (any(x in start_msg for x in from_lib_parts) \n",
    "            and any(x in start_msg for x in to_lib_parts) \n",
    "            and any(x in end_msg for x in cleanup_keywords)):\n",
    "            return True\n",
    "        if (any(x in end_msg for x in from_lib_parts) \n",
    "            and any(x in end_msg for x in to_lib_parts) \n",
    "            and any(x in start_msg for x in add_keywords)\n",
    "            and any(x in start_msg for x in from_lib_parts)):\n",
    "            return True\n",
    "        \"\"\"\n",
    "    return False\n",
    "confirmed_migrations = pd.read_excel(\"manual/confirmed-migrations-initial-examples.xlsx\")\n",
    "msgs = set(confirmed_migrations[\"startCommit\"]) | set(confirmed_migrations[\"endCommit\"])\n",
    "seem_true = []\n",
    "for idx, row in confirmed_migrations.iterrows():\n",
    "    seem_true.append(seem_like_migration(row[\"fromLib\"], row[\"toLib\"] ,row[\"startCommitMessage\"], row[\"endCommitMessage\"]))\n",
    "print(\"Recall: {}\".format(len([x for x in seem_true if x is True]) / len(seem_true)))\n",
    "confirmed_migrations[\"seemTrue\"] = seem_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5200"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_migrations = pd.read_csv(\"possible-migrations.csv\").fillna(\"\")\n",
    "seem_true = []\n",
    "for idx, row in possible_migrations.iterrows():\n",
    "    seem_true.append(seem_like_migration(row[\"fromLib\"], row[\"toLib\"] ,row[\"startCommitMessage\"], row[\"endCommitMessage\"]))\n",
    "possible_migrations[\"seemTrue\"] = seem_true\n",
    "possible_migrations[possible_migrations[\"seemTrue\"] == True].to_csv(\"possible-migrations-filtered.csv\", index=False)\n",
    "len(possible_migrations[possible_migrations[\"seemTrue\"] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 98, 101)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "migrations = possible_migrations[possible_migrations[\"seemTrue\"] == True]\n",
    "confirmed_rules = set(zip(migrations[\"fromLib\"], migrations[\"toLib\"]))\n",
    "confirmed_from_libs = set(migrations[\"fromLib\"])\n",
    "confirmed_to_libs = set(migrations[\"toLib\"])\n",
    "len(confirmed_rules), len(confirmed_from_libs), len(confirmed_to_libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyl_output = pd.read_csv(\"recommend-output-xyl.csv\")\n",
    "len(set(xyl_output[\"fromGroupArtifact\"]) & confirmed_from_libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
