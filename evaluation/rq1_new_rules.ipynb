{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_repo_commit(raw_str):\n",
    "    result = []\n",
    "    for item in raw_str.split(\" \"):\n",
    "        if len(item) == 0: \n",
    "            continue\n",
    "        repo, start, end, file = item.split(\";\")\n",
    "        result.append((repo, start, end, file))\n",
    "    return result\n",
    "rules = pd.read_csv(\"recommend-output.csv\")\n",
    "commits = pd.read_csv(\"test-recommend-output-wocDepSeq3-all-commits.csv\").fillna(\"\")\n",
    "confirmed = pd.read_excel(\"manual/confirmed-migrations.xlsx\")\n",
    "confirmed_commit_pairs = set(zip(confirmed[\"startCommit\"], confirmed[\"endCommit\"]))\n",
    "confirmed_rules = set(zip(confirmed[\"fromLib\"], confirmed[\"toLib\"]))\n",
    "commits[\"possibleCommits\"] = commits[\"possibleCommits\"].apply(parse_repo_commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient(\"mongodb://migration_helper:HeHMgt2020@da1.eecs.utk.edu:27020/migration_helper\"\n",
    "                           \"?authSource=migration_helper\").migration_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5287, 5287)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve all commit metadata\n",
    "commit_shas = set()\n",
    "commit_metadata = dict()\n",
    "for possible_commits in commits[\"possibleCommits\"]:\n",
    "    for repo, start, end, file in possible_commits:\n",
    "        commit_shas.update((start, end))\n",
    "for item in db.wocCommit.find({\"_id\": {\"$in\": list(commit_shas)}}):\n",
    "    commit_metadata[item[\"_id\"]] = item\n",
    "len(commit_shas), len(commit_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24870"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve all dep seq change in that commit\n",
    "commit_depchg = dict()\n",
    "for seq in db.wocDepSeq3.find():\n",
    "    for item in seq[\"seq\"]:\n",
    "        if item[\"commit\"] in commit_shas:\n",
    "            commit_depchg[(seq[\"repoName\"], seq[\"fileName\"], item[\"commit\"])] = item[\"changes\"]\n",
    "len(commit_depchg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule2count = {(row[\"fromGroupArtifact\"], row[\"toGroupArtifact\"]): row[\"ruleCount\"] for idx, row in rules.iterrows()}\n",
    "lib2info = {lib[\"name\"]: lib for lib in db.lioProject.find()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4250"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"recommend-output.csv\")\n",
    "ground_truth = pd.read_csv(\"ground-truth.csv\")\n",
    "existing_rules = set(zip(ground_truth[\"fromLib\"], ground_truth[\"toLib\"]))\n",
    "new_rules = []\n",
    "for from_lib, rows in results.groupby(by=\"fromGroupArtifact\"):\n",
    "    for to_lib in rows[\"toGroupArtifact\"][0:20]:\n",
    "        rule_count = 0\n",
    "        if (from_lib, to_lib) in rule2count:\n",
    "            rule_count = rule2count[(from_lib, to_lib)]\n",
    "        if (from_lib, to_lib) in existing_rules:\n",
    "            continue\n",
    "        new_rules.append({\n",
    "            \"fromLib\": from_lib,\n",
    "            \"toLib\": to_lib,\n",
    "            \"ruleCount\": rule_count,\n",
    "            \"isPossible\": False,\n",
    "            \"isConfirmed\": False,\n",
    "            \"fromLibHomepageURL\": lib2info[from_lib][\"homepageUrl\"],\n",
    "            \"toLibHomepageURL\":lib2info[to_lib][\"homepageUrl\"],\n",
    "            \"fromLibDescription\": lib2info[from_lib][\"description\"],\n",
    "            \"toLibDescription\": lib2info[to_lib][\"description\"],\n",
    "            \"fromLibRepositoryURL\": lib2info[from_lib][\"repositoryUrl\"],\n",
    "            \"toLibRepositoryURL\": lib2info[to_lib][\"repositoryUrl\"],\n",
    "            \"fromLibRepositoryDescription\": lib2info[from_lib][\"repositoryDescription\"],\n",
    "            \"toLibRepositoryDescription\": lib2info[to_lib][\"repositoryDescription\"],\n",
    "        })\n",
    "new_rules = pd.DataFrame(new_rules)\n",
    "len(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new_rules).to_csv(\"new-rules.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2933"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "candidates = set(zip(new_rules[\"fromLib\"], new_rules[\"toLib\"]))\n",
    "for from_lib, to_lib, possible_commits in zip(commits[\"fromLib\"], commits[\"toLib\"], commits[\"possibleCommits\"]):\n",
    "    for repo, start, end, file in possible_commits:\n",
    "        if (start, end) in confirmed_commit_pairs:\n",
    "            continue\n",
    "        if (from_lib, to_lib) not in candidates:\n",
    "            continue\n",
    "        data.append({\n",
    "            \"fromLib\": from_lib,\n",
    "            \"toLib\": to_lib,\n",
    "            \"repoName\": repo,\n",
    "            \"fileName\": file,\n",
    "            \"startCommit\": start,\n",
    "            \"endCommit\": end,\n",
    "            \"startCommitChanges\": \"\\n\".join(commit_depchg[(repo, file, start)]),\n",
    "            \"endCommitChanges\": \"\\n\".join(commit_depchg[(repo, file, end)]),\n",
    "            \"startCommitMessage\": commit_metadata[start][\"message\"],\n",
    "            \"endCommitMessage\": commit_metadata[end][\"message\"],\n",
    "            \"startCommitTime\": commit_metadata[start][\"timestamp\"],\n",
    "            \"endCommitTime\": commit_metadata[end][\"timestamp\"],\n",
    "        })\n",
    "data = pd.DataFrame(data).sort_values(by=[\"startCommit\", \"fromLib\"])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"possible-migrations-from-lib-2014-second-round.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.read_csv(\"possible-ground-truth-2014.csv\")\n",
    "confirmed_migrations = pd.read_excel(\"manual/confirmed-migrations.xlsx\")\n",
    "confirmed_rules = set(zip(confirmed_migrations[\"fromLib\"], confirmed_migrations[\"toLib\"]))\n",
    "rules = pd.read_csv(\"test-recommend-output-wocDepSeq3-all.csv\")\n",
    "len(confirmed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ground_truth = []\n",
    "for idx, row in ground_truth.iterrows():\n",
    "    from_lib, to_lib = row[\"fromGroupArtifact\"], row[\"toGroupArtifact\"]\n",
    "    rule_count = 0\n",
    "    if (from_lib, to_lib) in rule2count:\n",
    "        rule_count = rule2count[(from_lib, to_lib)]\n",
    "    new_ground_truth.append({\n",
    "        \"fromLib\": from_lib,\n",
    "        \"toLib\": to_lib,\n",
    "        \"ruleCount\": rule_count,\n",
    "        \"isPossible\": True,\n",
    "        \"isConfirmed\": row[\"dataConfirmed\"],\n",
    "        \"fromLibHomepageURL\": lib2info[from_lib][\"homepageUrl\"],\n",
    "        \"toLibHomepageURL\":lib2info[to_lib][\"homepageUrl\"],\n",
    "        \"fromLibDescription\": lib2info[from_lib][\"description\"],\n",
    "        \"toLibDescription\": lib2info[to_lib][\"description\"],\n",
    "        \"fromLibRepositoryURL\": lib2info[from_lib][\"repositoryUrl\"],\n",
    "        \"toLibRepositoryURL\": lib2info[to_lib][\"repositoryUrl\"],\n",
    "        \"fromLibRepositoryDescription\": lib2info[from_lib][\"repositoryDescription\"],\n",
    "        \"toLibRepositoryDescription\": lib2info[to_lib][\"repositoryDescription\"],\n",
    "    })\n",
    "for from_lib, to_lib in confirmed_rules:\n",
    "    rule_count = 0\n",
    "    if (from_lib, to_lib) in rule2count:\n",
    "        rule_count = rule2count[(from_lib, to_lib)]\n",
    "    if from_lib not in lib2info or to_lib not in lib2info:\n",
    "        continue\n",
    "    new_ground_truth.append({\n",
    "        \"fromLib\": from_lib,\n",
    "        \"toLib\": to_lib,\n",
    "        \"ruleCount\": rule_count,\n",
    "        \"isPossible\": True,\n",
    "        \"isConfirmed\": True,\n",
    "        \"fromLibHomepageURL\": lib2info[from_lib][\"homepageUrl\"],\n",
    "        \"toLibHomepageURL\":lib2info[to_lib][\"homepageUrl\"],\n",
    "        \"fromLibDescription\": lib2info[from_lib][\"description\"],\n",
    "        \"toLibDescription\": lib2info[to_lib][\"description\"],\n",
    "        \"fromLibRepositoryURL\": lib2info[from_lib][\"repositoryUrl\"],\n",
    "        \"toLibRepositoryURL\": lib2info[to_lib][\"repositoryUrl\"],\n",
    "        \"fromLibRepositoryDescription\": lib2info[from_lib][\"repositoryDescription\"],\n",
    "        \"toLibRepositoryDescription\": lib2info[to_lib][\"repositoryDescription\"],\n",
    "    })\n",
    "pd.DataFrame(new_ground_truth).drop_duplicates().sort_values(\n",
    "    by=[\"ruleCount\", \"fromLib\", \"toLib\"], ascending=[False, True, True]).to_csv(\"ground-truth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
