{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1588, 289)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = pd.read_csv(\"possible-ground-truth-2014.csv\")\n",
    "possible_rules = rules[rules[\"inDepSeq\"] > 0]\n",
    "confirmed_rules = rules[rules[\"dataConfirmed\"]]\n",
    "len(possible_rules), len(confirmed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4934676"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a precomputed API support file from last version\n",
    "# TODO: We should replace this with a better one\n",
    "# (from_lib, to_lib) -> counter (int)\n",
    "api_support = dict()\n",
    "api_support_df = pd.read_csv(\"../export/APISupport.csv\")\n",
    "libs = pd.read_csv(\"../export/GroupArtifact.csv\").fillna(\"\")\n",
    "id2lib = dict()\n",
    "for idx, row in libs.iterrows():\n",
    "    id2lib[row[\"id\"]] = row[\"groupId\"] + \":\" + row[\"artifactId\"]\n",
    "for idx, row in api_support_df.iterrows():\n",
    "    api_support[(id2lib[row[\"fromId\"]], id2lib[row[\"toId\"]])] = row[\"counter\"]\n",
    "len(api_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient(\"mongodb://migration_helper:HeHMgt2020@da1.eecs.utk.edu:27020/migration_helper\"\n",
    "                           \"?authSource=migration_helper\").migration_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404339"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = []\n",
    "for seq in db.wocDepSeq3.find():\n",
    "    seqs.append(seq)\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify depseq using the following heuristics:\n",
    "# 1. if a removed library does not exist in current sequence, the change is dropped\n",
    "# 2. if an added library is already added in current sequence, the change is dropped\n",
    "# 3. remove item with no dep change\n",
    "for seq in seqs:\n",
    "    curr_libs = set()\n",
    "    for item in seq[\"seq\"]:\n",
    "        added_libs = set(chg[1:] for chg in item[\"changes\"] if chg.startswith(\"+\") and chg[1:] not in curr_libs)\n",
    "        removed_libs = set(chg[1:] for chg in item[\"changes\"] if chg.startswith(\"-\") and chg[1:] in curr_libs)\n",
    "        curr_libs = (curr_libs | added_libs) - removed_libs\n",
    "        item[\"changes\"] = [\"+\" + lib for lib in added_libs] + [\"-\" + lib for lib in removed_libs]\n",
    "    seq[\"seq\"] = [item for item in seq[\"seq\"] if len(item[\"changes\"]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653309"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_ground_truth = pd.read_csv(\"possible-ground-truth-2014.csv\")\n",
    "from2tolibs = dict()\n",
    "for from_lib, rows in possible_ground_truth.groupby(by=\"fromGroupArtifact\"):\n",
    "    from2tolibs[from_lib] = list(rows[\"toGroupArtifact\"])\n",
    "# (from_lib, to_lib) -> {ruleFreq, concurrence, distance, apiSupport}\n",
    "all_rules = dict()\n",
    "for seq in seqs:\n",
    "    for i, item in enumerate(seq[\"seq\"]):\n",
    "        for chg in item[\"changes\"]:\n",
    "            if chg.startswith(\"-\") and chg[1:] in from2tolibs:\n",
    "                from_lib = chg[1:]\n",
    "                end_id = i\n",
    "                start_id = 0\n",
    "                for j in range(0, i + 1):\n",
    "                    if \"+\" + from_lib in seq[\"seq\"][j][\"changes\"]:\n",
    "                        start_id = j\n",
    "                occurred_to_libs = set()\n",
    "                for k in range(start_id, end_id + 1):\n",
    "                    for chg2 in seq[\"seq\"][k][\"changes\"]:\n",
    "                        if chg2.startswith(\"+\"):\n",
    "                            to_lib = chg2[1:]\n",
    "                            if to_lib == from_lib or to_lib in occurred_to_libs:\n",
    "                                continue\n",
    "                            occurred_to_libs.add(to_lib)\n",
    "                            if (from_lib, to_lib) in all_rules:\n",
    "                                all_rules[(from_lib, to_lib)][\"ruleFreq\"] += 1\n",
    "                                all_rules[(from_lib, to_lib)][\"distance\"].append(end_id - k)\n",
    "                            else:\n",
    "                                all_rules[(from_lib, to_lib)] = {\n",
    "                                    \"ruleFreq\": 1,\n",
    "                                    \"concurrence\": 0,\n",
    "                                    \"addedTogether\": 0,\n",
    "                                    \"distance\": [end_id - k],\n",
    "                                    \"apiCounter\": 0,\n",
    "                                }\n",
    "for seq in seqs:\n",
    "    for item in seq[\"seq\"]:\n",
    "        added = set()\n",
    "        for chg in item[\"changes\"]:\n",
    "            if chg.startswith(\"+\"):\n",
    "                added.add(chg[1:])\n",
    "        for i in added:\n",
    "            for j in added:\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if (i, j) in all_rules:\n",
    "                    all_rules[(i, j)][\"addedTogether\"] += 1\n",
    "                if (j, i) in all_rules:\n",
    "                    all_rules[(j, i)][\"addedTogether\"] += 1\n",
    "for seq in seqs:\n",
    "    lib_added = set()\n",
    "    for item in seq[\"seq\"]:\n",
    "        for chg in item[\"changes\"]:\n",
    "            if chg.startswith(\"+\"):\n",
    "                lib_added.add(chg[1:])\n",
    "    for i in lib_added:\n",
    "        for j in lib_added:\n",
    "            if i == j:\n",
    "                continue\n",
    "            if (i, j) in all_rules:\n",
    "                all_rules[(i, j)][\"concurrence\"] += 1\n",
    "            if (j, i) in all_rules:\n",
    "                all_rules[(j, i)][\"concurrence\"] += 1\n",
    "for rule in all_rules:\n",
    "    if rule in api_support:\n",
    "        all_rules[rule][\"apiCounter\"] = api_support[rule]\n",
    "    all_rules[rule][\"distance\"] = \";\".join([str(x) for x in all_rules[rule][\"distance\"]])\n",
    "len(all_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules = pd.DataFrame.from_dict(all_rules, orient=\"index\")\n",
    "all_rules.index.set_names([\"fromLib\", \"toLib\"], inplace=True)\n",
    "all_rules[\"isPossible\"] = False\n",
    "all_rules[\"isConfirmed\"] = False\n",
    "for from_lib, to_lib in zip(possible_rules[\"fromGroupArtifact\"], possible_rules[\"toGroupArtifact\"]):\n",
    "    if (from_lib, to_lib) not in all_rules.index:\n",
    "        continue\n",
    "    all_rules.loc[(from_lib, to_lib), \"isPossible\"] = True\n",
    "for from_lib, to_lib in zip(confirmed_rules[\"fromGroupArtifact\"], confirmed_rules[\"toGroupArtifact\"]):\n",
    "    if (from_lib, to_lib) not in all_rules.index:\n",
    "        continue\n",
    "    all_rules.loc[(from_lib, to_lib), \"isConfirmed\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules.to_csv(\"all-rules-with-metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
